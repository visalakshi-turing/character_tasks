{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User\n",
    "# - Realistic\n",
    "# - Consistent\n",
    "# - Colorful personality\n",
    "# - Coherent Follow ups\n",
    "\n",
    "# Assistant\n",
    "# - Tailors to user\n",
    "# - Maximally Helpful\n",
    "# - Code Quality\n",
    "#   - Optimal Code\n",
    "#   - Code Follows PEP8 Standards\n",
    "# - Text Quality \n",
    "#   - Spelling\n",
    "#   - Grammar\n",
    "#   - Capitalization & Punctuation\n",
    "#   - Information Density (Should be a sweet spot leaning on the concise side, but not too concise... definitely not too verbose)\n",
    "#   - Explains Code Well\n",
    "# - Markdown Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversations_Batch_2\n",
      "(308, 13)\n",
      "Conversations_Batch_3\n",
      "(336, 12)\n",
      "Conversations_Batch_4\n",
      "(734, 12)\n",
      "Conversations_Batch_5\n",
      "(2378, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_link</th>\n",
       "      <th>metadata__topic</th>\n",
       "      <th>assigned_to_email</th>\n",
       "      <th>completion_status</th>\n",
       "      <th>modified_question?</th>\n",
       "      <th>duration_mins</th>\n",
       "      <th>completion_date</th>\n",
       "      <th>comments</th>\n",
       "      <th>metadata__problem_type</th>\n",
       "      <th>metadata__target_length</th>\n",
       "      <th>review_status</th>\n",
       "      <th>reviewer_email</th>\n",
       "      <th>Team_Type(Internal/External)</th>\n",
       "      <th>metadata__type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>https://colab.research.google.com/drive/1cP6qz...</td>\n",
       "      <td>unit_testing_methodology &gt; test_ai_and_ml_models</td>\n",
       "      <td>patelia.a@turing.com</td>\n",
       "      <td>Done</td>\n",
       "      <td>FALSE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>modification</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>External</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>https://colab.research.google.com/drive/1dZpsB...</td>\n",
       "      <td>python_language_and_scripting &gt; advanced_netwo...</td>\n",
       "      <td>patelia.a@turing.com</td>\n",
       "      <td>Done</td>\n",
       "      <td>FALSE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>modification</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>External</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>https://colab.research.google.com/drive/1lHYB-...</td>\n",
       "      <td>algorithms &gt; by_data_structure &gt; trees</td>\n",
       "      <td>marcus.a@turing.com</td>\n",
       "      <td>Done</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>20</td>\n",
       "      <td>12/22/2023</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>2+</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>modification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>https://colab.research.google.com/drive/1rfNQU...</td>\n",
       "      <td>web_development &gt; web_services</td>\n",
       "      <td>abdullah.i@turing.com</td>\n",
       "      <td>Done</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>43</td>\n",
       "      <td>12/23/2023</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>2+</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>https://colab.research.google.com/drive/1d613I...</td>\n",
       "      <td>algorithms &gt; by_data_structure &gt; trees</td>\n",
       "      <td>ritesh.r@turing.com</td>\n",
       "      <td>Done</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>35</td>\n",
       "      <td>12/28/2023</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>2+</td>\n",
       "      <td>Reviewed</td>\n",
       "      <td>ruturaj.m@turing.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747</th>\n",
       "      <td>https://colab.research.google.com/drive/1Vg7LI...</td>\n",
       "      <td>Intermediate_Learning_Learn_to_use_some_tool__...</td>\n",
       "      <td>shaharyar.t@turing.com</td>\n",
       "      <td>Done</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>25</td>\n",
       "      <td>1/8/2024</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2751</th>\n",
       "      <td>https://colab.research.google.com/drive/1OFgjc...</td>\n",
       "      <td>Intermediate_Learning_Learn_to_use_some_tool__...</td>\n",
       "      <td>armas.j@turing.com</td>\n",
       "      <td>Done</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>45</td>\n",
       "      <td>1/5/2024</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2753</th>\n",
       "      <td>https://colab.research.google.com/drive/1qheya...</td>\n",
       "      <td>Intermediate_Write_unit_test_Explain_code_with...</td>\n",
       "      <td>toh.y@turing.com</td>\n",
       "      <td>Done</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>45</td>\n",
       "      <td>1/8/2024</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754</th>\n",
       "      <td>https://colab.research.google.com/drive/1XaQdN...</td>\n",
       "      <td>Intermediate_Write_unit_test_Explain_code_with...</td>\n",
       "      <td>edwin.n@turing.com</td>\n",
       "      <td>Done</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>50</td>\n",
       "      <td>1/8/2024</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>https://colab.research.google.com/drive/1l_uDM...</td>\n",
       "      <td>Intermediate_Write_unit_test_Explain_code_with...</td>\n",
       "      <td>toh.y@turing.com</td>\n",
       "      <td>Done</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>45</td>\n",
       "      <td>1/8/2024</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>722 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              task_link  \\\n",
       "193   https://colab.research.google.com/drive/1cP6qz...   \n",
       "194   https://colab.research.google.com/drive/1dZpsB...   \n",
       "308   https://colab.research.google.com/drive/1lHYB-...   \n",
       "310   https://colab.research.google.com/drive/1rfNQU...   \n",
       "712   https://colab.research.google.com/drive/1d613I...   \n",
       "...                                                 ...   \n",
       "2747  https://colab.research.google.com/drive/1Vg7LI...   \n",
       "2751  https://colab.research.google.com/drive/1OFgjc...   \n",
       "2753  https://colab.research.google.com/drive/1qheya...   \n",
       "2754  https://colab.research.google.com/drive/1XaQdN...   \n",
       "2755  https://colab.research.google.com/drive/1l_uDM...   \n",
       "\n",
       "                                        metadata__topic  \\\n",
       "193    unit_testing_methodology > test_ai_and_ml_models   \n",
       "194   python_language_and_scripting > advanced_netwo...   \n",
       "308              algorithms > by_data_structure > trees   \n",
       "310                      web_development > web_services   \n",
       "712              algorithms > by_data_structure > trees   \n",
       "...                                                 ...   \n",
       "2747  Intermediate_Learning_Learn_to_use_some_tool__...   \n",
       "2751  Intermediate_Learning_Learn_to_use_some_tool__...   \n",
       "2753  Intermediate_Write_unit_test_Explain_code_with...   \n",
       "2754  Intermediate_Write_unit_test_Explain_code_with...   \n",
       "2755  Intermediate_Write_unit_test_Explain_code_with...   \n",
       "\n",
       "           assigned_to_email completion_status modified_question?  \\\n",
       "193     patelia.a@turing.com              Done              FALSE   \n",
       "194     patelia.a@turing.com              Done              FALSE   \n",
       "308      marcus.a@turing.com              Done              FALSE   \n",
       "310    abdullah.i@turing.com              Done              FALSE   \n",
       "712      ritesh.r@turing.com              Done              FALSE   \n",
       "...                      ...               ...                ...   \n",
       "2747  shaharyar.t@turing.com              Done              FALSE   \n",
       "2751      armas.j@turing.com              Done              FALSE   \n",
       "2753        toh.y@turing.com              Done              FALSE   \n",
       "2754      edwin.n@turing.com              Done              FALSE   \n",
       "2755        toh.y@turing.com              Done              FALSE   \n",
       "\n",
       "     duration_mins completion_date comments metadata__problem_type  \\\n",
       "193                                                   modification   \n",
       "194                                                   modification   \n",
       "308             20      12/22/2023                             NaN   \n",
       "310             43      12/23/2023                             NaN   \n",
       "712             35      12/28/2023                             NaN   \n",
       "...            ...             ...      ...                    ...   \n",
       "2747            25        1/8/2024     None                    NaN   \n",
       "2751            45        1/5/2024     None                    NaN   \n",
       "2753            45        1/8/2024     None                    NaN   \n",
       "2754            50        1/8/2024     None                    NaN   \n",
       "2755            45        1/8/2024     None                    NaN   \n",
       "\n",
       "     metadata__target_length review_status        reviewer_email  \\\n",
       "193                        1                                       \n",
       "194                        1                                       \n",
       "308                       2+          test                  test   \n",
       "310                       2+          None                  None   \n",
       "712                       2+      Reviewed  ruturaj.m@turing.com   \n",
       "...                      ...           ...                   ...   \n",
       "2747                    None          None                  None   \n",
       "2751                    None          None                  None   \n",
       "2753                    None          None                  None   \n",
       "2754                    None          None                  None   \n",
       "2755                    None          None                  None   \n",
       "\n",
       "     Team_Type(Internal/External) metadata__type  \n",
       "193                      External            NaN  \n",
       "194                      External            NaN  \n",
       "308                           NaN   modification  \n",
       "310                           NaN          query  \n",
       "712                           NaN          query  \n",
       "...                           ...            ...  \n",
       "2747                          NaN           None  \n",
       "2751                          NaN           None  \n",
       "2753                          NaN           None  \n",
       "2754                          NaN           None  \n",
       "2755                          NaN           None  \n",
       "\n",
       "[722 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append('../../')\n",
    "import pandas as pd\n",
    "from src.sheets_utils import download_sheet_as_df\n",
    "\n",
    "service_account_file = '../../creds/google__sa.json'\n",
    "\n",
    "tracking_sheet_id = \"1qBU7Kvuuij2fxbqPxebReKMxWgIBmOIE5Gi4ZuX0j_4\"\n",
    "included_sheet_names = [\n",
    "    \"Conversations_Batch_2\",\n",
    "    \"Conversations_Batch_3\",\n",
    "    \"Conversations_Batch_4\",\n",
    "    \"Conversations_Batch_5\",\n",
    "]\n",
    "\n",
    "jupyter_gdrive_folder_ids = [\n",
    "    \"1Z1bdYMe2Qmo_vs-OaKDaYIiV3rIqLJH9\", # V0\n",
    "    \"1sfPFHkXYpKyY41V0pfz3Qw3k4VLy5Hvb\", # V1\n",
    "    \"1jV7WA5zB172DJUp7Z2XzHr62E6U6_NtY\",\n",
    "]\n",
    "\n",
    "delivery_sheet_id = \"1eUif5I8xhHU8fY0X9v8r2JI9hWPh7Dq_9VXpSIHwww4\"\n",
    "\n",
    "\n",
    "progress_batches = []\n",
    "for sheet_name in included_sheet_names:\n",
    "    print(sheet_name)\n",
    "    bdf = download_sheet_as_df(service_account_file, tracking_sheet_id, sheet_name)\n",
    "    progress_batches.append(bdf)\n",
    "    print(bdf.shape)\n",
    "\n",
    "df = pd.concat(progress_batches, ignore_index=True)\n",
    "completed_df = df[df[\"completion_status\"] == \"Done\"]\n",
    "\n",
    "delivered = pd.concat([\n",
    "    download_sheet_as_df(service_account_file, delivery_sheet_id, \"Batch 1\"),\n",
    "    download_sheet_as_df(service_account_file, delivery_sheet_id, \"Batch 2\"),\n",
    "    download_sheet_as_df(service_account_file, delivery_sheet_id, \"Batch 3\"),\n",
    "    download_sheet_as_df(service_account_file, delivery_sheet_id, \"Batch 4\"),\n",
    "], ignore_index=True)\n",
    "\n",
    "\n",
    "completed_to_be_delivered_df = completed_df[~completed_df[\"task_link\"].isin(delivered[\"task_link\"])]\n",
    "completed_to_be_delivered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '18l9F7WDEqk8zVEJtKPKddmGQMv5Ejpc7',\n",
       " 'metadata': {'topic': 'unit_testing_methodology > testing_asynchronous_code',\n",
       "  'topic__top_level': 'unit_testing_methodology',\n",
       "  'summary': 'User inquiring about testing async code and service availability.',\n",
       "  'number_of_turns': '2'},\n",
       " 'messages': [{'role': 'User',\n",
       "   'content': \"What's the proper way to test an async function that depends on an external service using mocks in pytest?\",\n",
       "   'type': 'markdown'},\n",
       "  {'role': 'Assistant',\n",
       "   'content': \"There are a few key steps to ensure that the tests are properly isolated and asynchronous behavior is handled correctly. Here's how:\\n\\n**1. Install Necessary Packages:**\\nEnsure you have `pytest`, `pytest-asyncio` (for async support), and `unittest.mock` (or `pytest-mock` for more features) installed.\\n\\n```shell\\npip install pytest pytest-asyncio\\n```\\n\\n\\n**4. Write a Test Using Pytest:**\\nUse the `pytest.mark.asyncio` decorator to mark your test as an async test. Use `unittest.mock` to create a mock of the external service. Within the test, replace the external service with a mock.\\n\\n```python\\nimport pytest\\nfrom unittest.mock import AsyncMock\\n\\n@pytest.mark.asyncio\\nasync def test_fetch_data():\\n    mock_api_client = AsyncMock()\\n    mock_api_client.get_data.return_value = 'mocked data'\\n\\n    result = await fetch_data(mock_api_client)\\n    assert result == 'mocked data'\\n```\\n\\nIn this test:\\n- `AsyncMock()` is used to create an asynchronous mock object.\\n- `mock_api_client.get_data.return_value` is set to a dummy value.\\n- The `fetch_data` function is called with the mocked client, and the result is asserted.\\n\\n**5. Running the Test:**\\nRun the tests using `pytest` in a shell environment.\\n\\n```shell\\npytest your_test_file.py\\n```\",\n",
       "   'type': 'markdown'},\n",
       "  {'role': 'User',\n",
       "   'content': 'What if I need to test whether the external service itself is up?',\n",
       "   'type': 'markdown'},\n",
       "  {'role': 'Assistant',\n",
       "   'content': 'It means making actual requests to the service and verifying the response. This kind of test is more of an integration test than a unit test. Here\\'s how, using `pytest`:\\n\\n**1. Understand the Implications:**\\nTesting external services directly can lead to flaky tests due to network issues, service downtime, or changes in the external API. It\\'s important to be aware of these factors and handle them appropriately in your tests.\\n\\n**2. Write a Test Function:**\\nCreate a test function that makes a request to the external service. This could be a simple health check endpoint or a specific function of the service.\\n\\n**3. Handle Timeouts and Exceptions:**\\nIt\\'s good practice to handle potential timeouts and exceptions that might occur due to network issues or service unavailability.\\n\\n**4. Consider Test Environment:**\\nBe mindful of the environment in which these tests run. Repeatedly hitting an external service might have implications like rate limiting or added costs.\\n\\n**5. Isolation from Unit Tests:**\\nKeep these tests separate from your unit tests. Unit tests should be quick and reliable, whereas these kinds of tests can be slower and less predictable. Consider using a different marker or placing them in a separate test directory.\\n\\n\\nHere\\'s an example:\\n\\n```python\\nimport requests\\nimport pytest\\n\\n# Test Function\\ndef test_external_service_up():\\n    response = requests.get(\\'https://api.external-service.com/health\\')\\n    assert response.status_code == 200\\n\\n\\n# Handle Timeouts and Exceptions\\ndef test_external_service_up():\\n    try:\\n        response = requests.get(\\'https://api.external-service.com/health\\', timeout=10)\\n        assert response.status_code == 200\\n    except requests.RequestException as e: DUMMYBEGIN\\n        pytest.fail(f\"Service check failed: {e}\")\\n```\\n\\nYou can run this test as part of your integration test suite. Ensure that the environment where the tests are run has access to the external service.\\n\\n```shell\\npytest integration_tests/\\n```',\n",
       "   'type': 'markdown'}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "from pydantic import BaseModel\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "\n",
    "api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "file_list = os.listdir(\"../../jsonl_conversations/Batch 4/\")\n",
    "random.seed(0)\n",
    "random_item = random.choice(file_list)\n",
    "\n",
    "with open(f\"../../jsonl_conversations/Batch 4/{random_item}\") as f:\n",
    "    conversation = json.load(f)\n",
    "\n",
    "conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "import nbformat\n",
    "from googleapiclient.discovery import build\n",
    "from google.oauth2.service_account import Credentials\n",
    "from googleapiclient.http import MediaIoBaseDownload, MediaFileUpload\n",
    "\n",
    "from src.llm_reviewer.notebook_parser import notebook_parser\n",
    "\n",
    "\n",
    "def get_colab_notebook(colab_link, sa_creds_path) -> nbformat.NotebookNode:\n",
    "    try:\n",
    "        # Extract file ID from the Colab link\n",
    "        file_id = colab_link.split('/drive/')[1].split('/')[0]\n",
    "    except IndexError:\n",
    "        raise ValueError(\"Invalid Colab link format\")\n",
    "\n",
    "    # Initialize Google Drive API\n",
    "    SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "    credentials = Credentials.from_service_account_file(sa_creds_path, scopes=SCOPES)\n",
    "    service = build('drive', 'v3', credentials=credentials)\n",
    "\n",
    "    # Download the file\n",
    "    try:\n",
    "        request = service.files().get_media(fileId=file_id)\n",
    "        fh = io.BytesIO()\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "\n",
    "        done = False\n",
    "        while not done:\n",
    "            status, done = downloader.next_chunk()\n",
    "            print(f\"Download {int(status.progress() * 100)}%.\")\n",
    "        \n",
    "        # Load as nbformat notebook\n",
    "        notebook = nbformat.reads(fh.getvalue().decode(), as_version=4)\n",
    "        return notebook\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading file: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from llama_index import ServiceContext, set_global_service_context\n",
    "from llama_index.program import OpenAIPydanticProgram\n",
    "from llama_index.callbacks import CallbackManager, TokenCountingHandler\n",
    "\n",
    "\n",
    "\n",
    "token_counter = TokenCountingHandler(\n",
    "    tokenizer=tiktoken.encoding_for_model(\"gpt-4-1106-preview\").encode\n",
    ")\n",
    "\n",
    "callback_manager = CallbackManager([token_counter])\n",
    "\n",
    "\n",
    "class Feedback(BaseModel):\n",
    "    score: int = Field(description=\"A score representing how good the conversation is in the given quality aspect, 1 is terrible, 5 is exemplary and flawless.\", ge=1, le=5)\n",
    "    issues: List[str] = Field(description=\"A concrete list of issues in the conversation. 15 words or less each.\")\n",
    "    praises: List[str] = Field(description=\"A concrete list of praise for exceptional behavior the conversation. 15 words or less each.\")\n",
    "\n",
    "\n",
    "class QualityAspect(BaseModel):\n",
    "    name: str = Field(description=\"The name of the quality aspect.\")\n",
    "    instruction: str = Field(description=\"Instructions & details on how to inspect this quality aspect.\")\n",
    "\n",
    "\n",
    "def inspect_conversation_quality_aspect(conversation: List[List[dict]], quality_aspect: QualityAspect):\n",
    "    \"\"\"Inspect a conversation for a given quality aspect.\"\"\"\n",
    "\n",
    "    prompt_template_str = \"\"\"\n",
    "    Given the following conversation, please rate the quality of the conversation according to the given quality aspect.\n",
    "    You are one of many specialized inspectors, so precisely focus on your quality aspect.\n",
    "\n",
    "    Quality Aspect:\n",
    "    {quality_aspect}\n",
    "\n",
    "    Conversation:\n",
    "    {conversation}\n",
    "    \"\"\"\n",
    "    program = OpenAIPydanticProgram.from_defaults(\n",
    "        llm=OpenAI(api_key=api_key, model=\"gpt-4-1106-preview\", temperature=0),\n",
    "        callback_manager=callback_manager,\n",
    "        output_cls=Feedback, \n",
    "        prompt_template_str=prompt_template_str, \n",
    "    )\n",
    "    output = program( \n",
    "        quality_aspect=quality_aspect.model_dump(),\n",
    "        conversation=conversation[\"messages\"],\n",
    "        description=\"Judge the quality of the conversation according to the given quality aspect.\"\n",
    "    )\n",
    "    return output\n",
    "\n",
    "\n",
    "def inspect_all_conversation_quality_aspects(conversation) -> dict:\n",
    "    \"\"\"Inspect a conversation for all quality aspects.\"\"\"\n",
    "    \n",
    "    user_qualities = [\n",
    "        QualityAspect(\n",
    "            name=\"Natural & Realistic\", \n",
    "            instruction=\"\"\"\n",
    "            How does the user interaction resemble a real conversation and interactions a real user would have with a highly intelligent coding assistant.\n",
    "\n",
    "            ONLY JUDGE THE USER MESSAGES. DO NOT JUDGE THE ASSISTANT MESSAGES.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        QualityAspect(\n",
    "            name=\"Consistent\", \n",
    "            instruction=\"\"\"\n",
    "            How consistent is the user's personality throughout the conversation.\n",
    "\n",
    "            ONLY JUDGE THE USER MESSAGES. DO NOT JUDGE THE ASSISTANT MESSAGES.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        QualityAspect(\n",
    "            name=\"Colorful Personality\", \n",
    "            instruction=\"\"\"\n",
    "            How colorful is the user's personality throughout the conversation, Do any personality traits shine through? If it's just standard don't rate it highly.\n",
    "\n",
    "            ONLY JUDGE THE USER MESSAGES. DO NOT JUDGE THE ASSISTANT MESSAGES.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        QualityAspect(\n",
    "            name=\"Coherent Follow ups\", \n",
    "            instruction=\"\"\"\n",
    "            How coherent are the user's follow up messages to the assistant's messages in the conversation as a whole.\n",
    "            Ideally, the user would incrementally build on the conversation to achieve their goal.\n",
    "\n",
    "            ONLY JUDGE THE USER MESSAGES. DO NOT JUDGE THE ASSISTANT MESSAGES.\n",
    "            \"\"\"\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    assistant_qualities = [\n",
    "        QualityAspect(\n",
    "            name=\"Tailors to User\", \n",
    "            instruction=\"\"\"\n",
    "            How well does the assistant tailor the way it's responding to the user's needs and preferences.\n",
    "\n",
    "            ONLY JUDGE THE ASSISTANT MESSAGES. DO NOT JUDGE THE USER MESSAGES.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        QualityAspect(\n",
    "            name=\"Maximally Helpful\", \n",
    "            instruction=\"\"\"\n",
    "            How helpful is the assistant in helping the user achieve their goals.\n",
    "\n",
    "            ONLY JUDGE THE ASSISTANT MESSAGES. DO NOT JUDGE THE USER MESSAGES.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        QualityAspect(\n",
    "            name=\"Code Quality\", \n",
    "            instruction=\"\"\"\n",
    "            How good is the code that the assistant generates.\n",
    "            Qualities:\n",
    "            #   - Correctness\n",
    "            #   - Optimality\n",
    "            #   - PEP8 Compliance & Readability\n",
    "\n",
    "            ONLY JUDGE THE ASSISTANT MESSAGES. DO NOT JUDGE THE USER MESSAGES.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        QualityAspect(\n",
    "            name=\"Text Quality\", \n",
    "            instruction=\"\"\"\n",
    "            How good is the text that the assistant generates.\n",
    "            Qualities:\n",
    "            #   - Spelling\n",
    "            #   - Grammar\n",
    "            #   - Capitalization & Punctuation\n",
    "            #   - Information Density (Should be a sweet spot leaning on the concise side, but not too concise... definitely not too verbose)\n",
    "            #   - Explains Code Well\n",
    "\n",
    "            ONLY JUDGE THE ASSISTANT MESSAGES. DO NOT JUDGE THE USER MESSAGES.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        QualityAspect(\n",
    "            name=\"Markdown Formatting\", \n",
    "            instruction=\"\"\"\n",
    "            How good is the markdown formatting that the assistant generates. Is it leveraging markdown syntax tools to maximize the readability of the text?\n",
    "\n",
    "            ONLY JUDGE THE ASSISTANT MESSAGES. DO NOT JUDGE THE USER MESSAGES.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        QualityAspect(\n",
    "            name=\"Richness\",\n",
    "            instruction=\"\"\"\n",
    "            How rich is the assistant's response to the user's messages. Does the code and text capitalize on opportunities to provide in-depth and diverse insights?\n",
    "\n",
    "            ONLY JUDGE THE ASSISTANT MESSAGES. DO NOT JUDGE THE USER MESSAGES.\n",
    "            \"\"\"\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    quality_results = {}\n",
    "    for quality_aspect in user_qualities:\n",
    "        r = inspect_conversation_quality_aspect(conversation, quality_aspect)\n",
    "        quality_results[f\"User - {quality_aspect.name}\"] = r.model_dump()\n",
    "    for quality_aspect in assistant_qualities:\n",
    "        r = inspect_conversation_quality_aspect(conversation, quality_aspect)\n",
    "        quality_results[f\"Assistant - {quality_aspect.name}\"] = r.model_dump()\n",
    "\n",
    "    return quality_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/722 [00:01<16:54,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading file: <HttpError 404 when requesting https://www.googleapis.com/drive/v3/files/1rfNQU__74pEdovonm_-u6yrhF0UsAa2C?alt=media returned \"File not found: 1rfNQU__74pEdovonm_-u6yrhF0UsAa2C.\". Details: \"[{'message': 'File not found: 1rfNQU__74pEdovonm_-u6yrhF0UsAa2C.', 'domain': 'global', 'reason': 'notFound', 'location': 'fileId', 'locationType': 'parameter'}]\">\n",
      "'NoneType' object has no attribute 'cells'\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/722 [00:29<3:25:36, 17.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/722 [00:34<2:18:00, 11.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/722 [00:37<1:03:15,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/722 [00:39<36:18,  3.05s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 10/722 [00:40<17:21,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 11/722 [00:41<16:05,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 13/722 [00:42<14:03,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 14/722 [00:44<13:34,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 17/722 [00:46<12:16,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 19/722 [00:48<09:36,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 23/722 [00:54<12:34,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 25/722 [00:55<09:22,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 26/722 [00:56<08:46,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 27/722 [00:59<16:14,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 28/722 [01:00<15:03,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 29/722 [01:01<14:49,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 31/722 [01:03<11:22,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 33/722 [01:13<30:51,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 35/722 [01:17<26:11,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 36/722 [01:19<25:40,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 39/722 [01:23<16:58,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 41/722 [01:25<12:44,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 43/722 [01:26<10:01,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 44/722 [01:30<19:37,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 45/722 [01:32<21:04,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 46/722 [01:35<24:22,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 47/722 [01:39<29:30,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 48/722 [01:39<22:50,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 53/722 [01:43<09:30,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 54/722 [01:44<08:17,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 56/722 [01:48<15:23,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 58/722 [01:52<19:29,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 59/722 [01:53<17:24,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 62/722 [02:00<17:35,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 63/722 [02:03<21:23,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 64/722 [02:05<23:37,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 66/722 [02:11<24:49,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 68/722 [02:14<19:37,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 72/722 [02:18<10:16,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 74/722 [02:22<15:41,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 75/722 [02:24<17:31,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 77/722 [02:31<27:46,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 80/722 [02:35<17:06,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 83/722 [02:38<13:44,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 84/722 [02:39<11:37,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 87/722 [02:45<14:36,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 88/722 [02:46<16:20,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 89/722 [02:48<16:20,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 90/722 [02:49<13:36,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 93/722 [02:54<14:21,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 94/722 [02:55<12:49,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 98/722 [02:59<09:23,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 99/722 [03:00<07:21,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.Download 100%.\n",
      "\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 100/722 [03:02<12:42,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 102/722 [03:08<18:40,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 103/722 [03:12<25:00,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 104/722 [03:14<24:11,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 106/722 [03:15<15:39,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 107/722 [03:16<13:46,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 108/722 [03:18<13:43,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 110/722 [03:23<20:36,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 111/722 [03:25<18:43,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 115/722 [03:29<10:24,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 116/722 [03:30<10:21,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 117/722 [03:30<07:42,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 118/722 [03:34<17:40,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 119/722 [03:37<18:38,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 121/722 [03:39<15:36,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 123/722 [03:41<11:15,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 124/722 [03:43<13:15,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 127/722 [03:46<10:15,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 129/722 [03:49<12:12,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 132/722 [03:54<12:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 135/722 [04:01<17:28,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 136/722 [04:03<16:00,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 137/722 [04:04<15:08,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 140/722 [04:10<16:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 141/722 [04:12<15:41,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 142/722 [04:13<15:08,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 143/722 [04:14<13:26,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 144/722 [04:15<11:54,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 146/722 [04:16<07:59,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 148/722 [04:19<11:20,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 150/722 [04:23<13:30,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 152/722 [04:24<09:42,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 154/722 [04:26<09:16,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 155/722 [04:28<10:57,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 156/722 [04:30<15:07,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 157/722 [04:31<13:04,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 158/722 [04:35<18:26,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 160/722 [04:38<16:36,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 161/722 [04:41<19:20,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 162/722 [04:43<19:03,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 165/722 [04:44<10:24,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 167/722 [04:55<24:40,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 168/722 [04:56<21:09,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 171/722 [04:58<10:21,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 172/722 [04:59<10:31,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 173/722 [05:00<11:03,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 174/722 [05:01<11:01,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 175/722 [05:02<10:35,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 177/722 [05:04<08:17,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 179/722 [05:05<07:21,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 180/722 [05:08<11:22,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 181/722 [05:09<11:35,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 182/722 [05:11<12:24,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 183/722 [05:14<15:52,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 186/722 [05:23<19:39,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 187/722 [05:23<14:54,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 188/722 [05:25<14:06,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 191/722 [05:28<10:15,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 192/722 [05:29<11:02,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 194/722 [05:31<07:52,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 196/722 [05:32<06:16,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 197/722 [05:34<09:59,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 198/722 [05:38<16:44,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 201/722 [05:41<10:57,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 202/722 [05:42<10:39,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 203/722 [05:44<12:13,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 204/722 [05:45<11:42,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 206/722 [05:47<08:35,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 208/722 [05:49<08:50,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 210/722 [05:52<09:34,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 213/722 [05:59<12:31,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 214/722 [06:02<17:36,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 215/722 [06:05<20:15,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 217/722 [06:07<13:59,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 219/722 [06:09<10:05,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 220/722 [06:10<08:24,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 222/722 [06:14<12:17,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 223/722 [06:15<12:34,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 224/722 [06:18<16:19,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 226/722 [06:21<13:40,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 228/722 [06:24<12:58,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 229/722 [06:26<11:58,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 230/722 [06:26<09:28,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 232/722 [06:31<13:13,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 233/722 [06:33<16:11,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 235/722 [06:36<13:16,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 236/722 [06:38<13:45,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 237/722 [06:38<10:12,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 238/722 [06:40<11:28,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 240/722 [06:43<11:02,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joe96/projects/turing/character.ai/character_tasks/venv/lib/python3.9/site-packages/nbformat/__init__.py:93: MissingIDFieldWarning: Code cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.\n",
      "  validate(nb)\n",
      " 34%|███▎      | 242/722 [06:47<13:01,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 246/722 [06:49<05:27,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 247/722 [06:51<08:35,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 251/722 [06:59<11:35,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 252/722 [07:01<10:54,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 253/722 [07:02<10:09,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 254/722 [07:04<11:22,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 255/722 [07:06<12:54,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 256/722 [07:07<11:32,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 257/722 [07:10<15:26,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 259/722 [07:13<13:14,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 260/722 [07:15<13:33,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 261/722 [07:16<10:55,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 263/722 [07:20<13:40,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 264/722 [07:22<13:15,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 267/722 [07:26<09:58,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 271/722 [07:32<09:17,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 273/722 [07:34<07:07,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 274/722 [07:34<06:15,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 275/722 [07:36<07:35,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 276/722 [07:37<07:41,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 277/722 [07:38<07:40,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 278/722 [07:39<08:05,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 280/722 [07:43<10:11,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 281/722 [07:44<10:38,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 282/722 [07:49<17:02,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 286/722 [07:53<08:45,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 287/722 [07:55<08:58,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 289/722 [07:55<05:49,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 290/722 [07:57<06:53,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 291/722 [07:57<06:05,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 293/722 [08:04<12:21,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 295/722 [08:06<10:08,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 296/722 [08:08<11:18,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 298/722 [08:12<12:27,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 300/722 [08:13<08:27,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 301/722 [08:14<08:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 302/722 [08:15<07:24,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 303/722 [08:16<07:38,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 304/722 [08:19<11:32,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 307/722 [08:23<09:05,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 309/722 [08:24<05:37,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 310/722 [08:25<05:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 311/722 [08:26<05:26,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 312/722 [08:34<21:50,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 315/722 [08:39<13:26,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 316/722 [08:41<13:23,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 317/722 [08:42<12:18,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 318/722 [08:43<10:30,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 319/722 [08:45<12:22,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 320/722 [08:48<13:05,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 322/722 [08:49<08:34,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 323/722 [08:50<07:11,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 325/722 [08:54<10:26,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 328/722 [08:59<09:09,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 330/722 [09:03<10:31,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 331/722 [09:05<09:54,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 333/722 [09:05<05:57,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 334/722 [09:05<04:45,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 335/722 [09:08<07:59,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 336/722 [09:08<05:54,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 338/722 [09:14<11:31,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 339/722 [09:15<10:32,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 341/722 [09:19<10:33,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 342/722 [09:22<12:30,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 344/722 [09:24<09:11,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 345/722 [09:24<07:47,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 347/722 [09:31<13:01,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 350/722 [09:35<08:53,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 351/722 [09:36<08:18,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 352/722 [09:36<07:06,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 353/722 [09:37<06:09,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 354/722 [09:42<14:02,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 357/722 [09:46<08:20,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 360/722 [09:51<07:51,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 362/722 [09:53<08:04,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 364/722 [09:57<08:39,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 365/722 [09:59<09:08,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 369/722 [10:03<05:52,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 370/722 [10:04<05:34,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 371/722 [10:05<05:18,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 372/722 [10:09<10:16,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 374/722 [10:12<09:01,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 376/722 [10:16<10:41,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 377/722 [10:18<10:57,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 378/722 [10:20<09:47,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 379/722 [10:21<08:14,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 380/722 [10:22<07:28,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 382/722 [10:25<08:05,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 384/722 [10:27<06:11,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 386/722 [10:34<12:12,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 389/722 [10:44<12:35,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 392/722 [10:45<05:49,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 393/722 [10:50<11:56,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 394/722 [10:51<10:47,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 395/722 [10:54<12:26,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 397/722 [10:56<08:40,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 399/722 [10:58<07:21,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 402/722 [11:05<08:37,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 403/722 [11:06<06:39,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 404/722 [11:08<07:28,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 406/722 [11:09<05:37,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 407/722 [11:10<05:34,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 410/722 [11:12<03:39,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 411/722 [11:14<05:30,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 412/722 [11:15<05:28,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 413/722 [11:17<06:39,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 414/722 [11:20<08:38,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 415/722 [11:21<07:38,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 416/722 [11:26<12:52,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 419/722 [11:30<08:09,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 421/722 [11:33<07:56,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 422/722 [11:35<08:28,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 423/722 [11:36<08:07,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 425/722 [11:41<09:06,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 427/722 [11:44<07:48,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 430/722 [11:47<06:39,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 433/722 [11:54<07:34,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 434/722 [11:55<06:56,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 437/722 [11:59<06:17,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 439/722 [12:03<07:29,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 440/722 [12:04<06:46,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 444/722 [12:10<05:46,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 446/722 [12:11<04:05,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 448/722 [12:15<06:00,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 450/722 [12:18<06:18,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 452/722 [12:22<07:15,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 454/722 [12:25<06:34,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 457/722 [12:29<05:16,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 459/722 [12:33<07:24,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 462/722 [12:37<05:28,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 465/722 [12:39<03:05,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 467/722 [12:43<05:14,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 469/722 [12:46<05:20,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 470/722 [12:48<07:15,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 472/722 [12:52<06:28,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 473/722 [12:55<09:13,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 475/722 [12:58<07:05,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 477/722 [13:00<05:08,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 478/722 [13:01<05:16,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 479/722 [13:02<04:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 482/722 [13:07<04:36,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 483/722 [13:14<11:31,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 485/722 [13:15<06:27,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 489/722 [13:19<03:39,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 490/722 [13:20<04:29,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 491/722 [13:21<04:25,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 493/722 [13:23<03:22,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 494/722 [13:25<05:11,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 496/722 [13:30<06:38,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 497/722 [13:31<05:37,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 500/722 [13:37<06:07,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 505/722 [13:44<04:30,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 506/722 [13:45<04:10,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 508/722 [13:49<05:09,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 509/722 [13:52<06:11,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 510/722 [13:55<07:26,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 513/722 [13:59<05:21,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 514/722 [14:00<05:12,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 516/722 [14:06<06:39,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 518/722 [14:07<04:29,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 520/722 [14:08<03:10,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 521/722 [14:09<03:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 522/722 [14:10<03:04,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 524/722 [14:11<02:16,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 525/722 [14:13<03:38,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 526/722 [14:14<03:14,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 527/722 [14:18<06:08,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 528/722 [14:23<09:12,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 530/722 [14:26<07:13,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 532/722 [14:28<04:54,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 533/722 [14:31<05:47,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 535/722 [14:35<05:24,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 536/722 [14:36<05:12,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 537/722 [14:38<05:32,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 538/722 [14:40<05:08,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 540/722 [14:42<03:50,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 542/722 [14:42<02:16,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 543/722 [14:44<03:19,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-1106-preview in organization org-qaullJSZer21IVpEVxBDy6ak on tokens per min (TPM): Limit 600000, Used 598362, Requested 1779. Please try again in 14ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 544/722 [14:45<03:12,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 546/722 [14:46<02:08,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 547/722 [14:48<03:29,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 548/722 [14:50<04:04,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 549/722 [14:51<03:15,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-1106-preview in organization org-qaullJSZer21IVpEVxBDy6ak on tokens per min (TPM): Limit 600000, Used 597847, Requested 2855. Please try again in 70ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 551/722 [14:53<03:16,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-1106-preview in organization org-qaullJSZer21IVpEVxBDy6ak on tokens per min (TPM): Limit 600000, Used 598244, Requested 2386. Please try again in 62ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 552/722 [14:54<02:46,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 553/722 [14:55<02:43,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 554/722 [14:56<03:15,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 556/722 [15:00<04:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 557/722 [15:04<06:38,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-1106-preview in organization org-qaullJSZer21IVpEVxBDy6ak on tokens per min (TPM): Limit 600000, Used 597752, Requested 3524. Please try again in 127ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 559/722 [15:05<03:48,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 560/722 [15:09<05:15,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 563/722 [15:13<03:42,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 564/722 [15:15<04:25,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 566/722 [15:19<04:12,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 568/722 [15:23<04:51,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 570/722 [15:25<03:13,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 573/722 [15:29<03:02,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-1106-preview in organization org-qaullJSZer21IVpEVxBDy6ak on tokens per min (TPM): Limit 600000, Used 598106, Requested 4482. Please try again in 258ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 575/722 [15:30<02:25,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 576/722 [15:32<03:02,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4-1106-preview in organization org-qaullJSZer21IVpEVxBDy6ak on tokens per min (TPM): Limit 600000, Used 599241, Requested 1908. Please try again in 114ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 578/722 [15:34<02:19,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 579/722 [15:36<03:05,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 580/722 [15:37<03:02,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 581/722 [15:39<03:19,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 582/722 [15:41<03:38,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 583/722 [15:44<04:25,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 585/722 [15:46<03:21,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 586/722 [15:48<03:27,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 588/722 [15:48<01:59,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 590/722 [15:52<02:42,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 592/722 [15:53<01:58,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 595/722 [15:54<01:04,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 596/722 [16:00<04:19,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 598/722 [16:07<05:14,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 599/722 [16:08<04:13,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 601/722 [16:15<05:19,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 603/722 [16:15<02:57,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 605/722 [16:20<03:37,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 606/722 [16:21<02:53,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 607/722 [16:24<03:42,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 610/722 [16:28<02:50,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 611/722 [16:29<02:23,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 613/722 [16:31<02:10,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 615/722 [16:36<03:12,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 617/722 [16:37<02:11,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 619/722 [16:43<03:07,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 620/722 [16:44<02:51,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 622/722 [16:45<01:44,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 626/722 [16:48<01:14,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 627/722 [16:54<03:27,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 629/722 [17:02<04:12,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 634/722 [17:06<01:21,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 635/722 [17:09<01:56,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 636/722 [17:13<03:03,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 639/722 [17:16<01:45,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 641/722 [17:18<01:33,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 642/722 [17:20<01:55,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 644/722 [17:21<01:16,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 645/722 [17:23<01:22,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 646/722 [17:23<01:08,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 647/722 [17:26<01:43,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 649/722 [17:28<01:29,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 650/722 [17:30<01:34,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 651/722 [17:31<01:36,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 653/722 [17:37<02:05,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 655/722 [17:41<02:03,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 656/722 [17:43<02:04,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 658/722 [17:44<01:26,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 660/722 [17:50<02:00,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 662/722 [17:53<01:38,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 663/722 [17:55<01:51,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 664/722 [17:57<01:43,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 666/722 [17:58<00:59,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 667/722 [17:58<00:47,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 668/722 [18:00<01:02,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 671/722 [18:04<01:03,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 672/722 [18:05<00:52,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 673/722 [18:06<00:58,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 675/722 [18:08<00:43,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 677/722 [18:11<00:59,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 678/722 [18:12<00:53,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 680/722 [18:17<01:08,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 682/722 [18:23<01:27,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 683/722 [18:24<01:18,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 684/722 [18:26<01:11,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 686/722 [18:27<00:47,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 687/722 [18:28<00:40,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 689/722 [18:29<00:26,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 690/722 [18:31<00:32,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Download 100%.\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 691/722 [18:34<00:52,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 693/722 [18:34<00:28,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 100%.\n",
      "Download 100%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 722/722 [19:25<00:00,  1.61s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "results = []\n",
    "# def process_file(file):\n",
    "#     with open(f\"../../jsonl_conversations/Batch 4/{file}\") as f:\n",
    "#         conversation = json.load(f)\n",
    "#     output = inspect_all_conversation_quality_aspects(conversation)\n",
    "#     record = {\n",
    "#         \"id\": conversation[\"id\"],\n",
    "#         \"colab_link\": f\"https://colab.research.google.com/drive/{conversation['id']}\"\n",
    "#     }\n",
    "#     record.update(output)\n",
    "#     return record\n",
    "\n",
    "# with concurrent.futures.ThreadPoolExecutor(max_workers=30) as executor:\n",
    "#     futures = [executor.submit(process_file, file) for file in file_list[:60]]\n",
    "#     progress_bar = tqdm(total=len(futures))\n",
    "#     for future in concurrent.futures.as_completed(futures):\n",
    "#         results.append(future.result())\n",
    "#         progress_bar.update(1)\n",
    "#     progress_bar.close()\n",
    "\n",
    "\n",
    "def process_colab_link(colab_link):\n",
    "    try:\n",
    "        notebook = notebook_parser(get_colab_notebook(colab_link, service_account_file))\n",
    "        output = inspect_all_conversation_quality_aspects(notebook)\n",
    "        record = {\n",
    "            \"colab_link\": colab_link\n",
    "        }\n",
    "        record.update(output)\n",
    "        return record\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "colab_links = completed_to_be_delivered_df[\"task_link\"].tolist()\n",
    "colab_links = [link.split(\"#\")[0] for link in colab_links]\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=30) as executor:\n",
    "    futures = [executor.submit(process_colab_link, colab_link) for colab_link in colab_links]\n",
    "    progress_bar = tqdm(total=len(futures))\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        results.append(future.result())\n",
    "        progress_bar.update(1)\n",
    "    progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [r for r in results if r is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colab_link</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>min_score</th>\n",
       "      <th>avg_user_score</th>\n",
       "      <th>avg_assistant_score</th>\n",
       "      <th>Assistant - Richness - score</th>\n",
       "      <th>Assistant - Tailors to User - score</th>\n",
       "      <th>User - Colorful Personality - score</th>\n",
       "      <th>User - Natural &amp; Realistic - score</th>\n",
       "      <th>User - Consistent - score</th>\n",
       "      <th>Assistant - Code Quality - score</th>\n",
       "      <th>Assistant - Text Quality - score</th>\n",
       "      <th>User - Coherent Follow ups - score</th>\n",
       "      <th>Assistant - Maximally Helpful - score</th>\n",
       "      <th>Assistant - Markdown Formatting - score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://colab.research.google.com/drive/175sjD...</td>\n",
       "      <td>4.875000</td>\n",
       "      <td>4</td>\n",
       "      <td>4.75</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://colab.research.google.com/drive/14JlJx...</td>\n",
       "      <td>4.708333</td>\n",
       "      <td>4</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://colab.research.google.com/drive/1ByZOC...</td>\n",
       "      <td>4.791667</td>\n",
       "      <td>4</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://colab.research.google.com/drive/1qdJCb...</td>\n",
       "      <td>4.291667</td>\n",
       "      <td>3</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://colab.research.google.com/drive/1PLC-p...</td>\n",
       "      <td>4.541667</td>\n",
       "      <td>3</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>https://colab.research.google.com/drive/1SesHn...</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>https://colab.research.google.com/drive/1NscBf...</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>https://colab.research.google.com/drive/1FVLxb...</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>https://colab.research.google.com/drive/1qheya...</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>https://colab.research.google.com/drive/1l_uDM...</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>1</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>715 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            colab_link  avg_score  min_score  \\\n",
       "0    https://colab.research.google.com/drive/175sjD...   4.875000          4   \n",
       "1    https://colab.research.google.com/drive/14JlJx...   4.708333          4   \n",
       "2    https://colab.research.google.com/drive/1ByZOC...   4.791667          4   \n",
       "3    https://colab.research.google.com/drive/1qdJCb...   4.291667          3   \n",
       "4    https://colab.research.google.com/drive/1PLC-p...   4.541667          3   \n",
       "..                                                 ...        ...        ...   \n",
       "710  https://colab.research.google.com/drive/1SesHn...   4.333333          1   \n",
       "711  https://colab.research.google.com/drive/1NscBf...   4.333333          1   \n",
       "712  https://colab.research.google.com/drive/1FVLxb...   4.250000          1   \n",
       "713  https://colab.research.google.com/drive/1qheya...   4.250000          1   \n",
       "714  https://colab.research.google.com/drive/1l_uDM...   3.916667          1   \n",
       "\n",
       "     avg_user_score  avg_assistant_score  Assistant - Richness - score  \\\n",
       "0              4.75             5.000000                             5   \n",
       "1              4.75             4.666667                             4   \n",
       "2              4.75             4.833333                             5   \n",
       "3              4.25             4.333333                             4   \n",
       "4              4.75             4.333333                             4   \n",
       "..              ...                  ...                           ...   \n",
       "710            4.00             4.666667                             4   \n",
       "711            4.00             4.666667                             4   \n",
       "712            4.00             4.500000                             4   \n",
       "713            4.00             4.500000                             4   \n",
       "714            4.00             3.833333                             3   \n",
       "\n",
       "     Assistant - Tailors to User - score  User - Colorful Personality - score  \\\n",
       "0                                      5                                    4   \n",
       "1                                      5                                    4   \n",
       "2                                      5                                    4   \n",
       "3                                      4                                    3   \n",
       "4                                      5                                    4   \n",
       "..                                   ...                                  ...   \n",
       "710                                    5                                    1   \n",
       "711                                    5                                    1   \n",
       "712                                    5                                    1   \n",
       "713                                    5                                    1   \n",
       "714                                    4                                    1   \n",
       "\n",
       "     User - Natural & Realistic - score  User - Consistent - score  \\\n",
       "0                                     5                          5   \n",
       "1                                     5                          5   \n",
       "2                                     5                          5   \n",
       "3                                     4                          5   \n",
       "4                                     5                          5   \n",
       "..                                  ...                        ...   \n",
       "710                                   5                          5   \n",
       "711                                   5                          5   \n",
       "712                                   5                          5   \n",
       "713                                   5                          5   \n",
       "714                                   5                          5   \n",
       "\n",
       "     Assistant - Code Quality - score  Assistant - Text Quality - score  \\\n",
       "0                                   5                                 5   \n",
       "1                                   4                                 5   \n",
       "2                                   4                                 5   \n",
       "3                                   4                                 5   \n",
       "4                                   3                                 5   \n",
       "..                                ...                               ...   \n",
       "710                                 5                                 4   \n",
       "711                                 4                                 5   \n",
       "712                                 4                                 5   \n",
       "713                                 4                                 4   \n",
       "714                                 4                                 4   \n",
       "\n",
       "     User - Coherent Follow ups - score  \\\n",
       "0                                     5   \n",
       "1                                     5   \n",
       "2                                     5   \n",
       "3                                     5   \n",
       "4                                     5   \n",
       "..                                  ...   \n",
       "710                                   5   \n",
       "711                                   5   \n",
       "712                                   5   \n",
       "713                                   5   \n",
       "714                                   5   \n",
       "\n",
       "     Assistant - Maximally Helpful - score  \\\n",
       "0                                        5   \n",
       "1                                        5   \n",
       "2                                        5   \n",
       "3                                        5   \n",
       "4                                        5   \n",
       "..                                     ...   \n",
       "710                                      5   \n",
       "711                                      5   \n",
       "712                                      5   \n",
       "713                                      5   \n",
       "714                                      4   \n",
       "\n",
       "     Assistant - Markdown Formatting - score  \n",
       "0                                          5  \n",
       "1                                          5  \n",
       "2                                          5  \n",
       "3                                          4  \n",
       "4                                          4  \n",
       "..                                       ...  \n",
       "710                                        5  \n",
       "711                                        5  \n",
       "712                                        4  \n",
       "713                                        5  \n",
       "714                                        4  \n",
       "\n",
       "[715 rows x 15 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cleanup scores from previous run\n",
    "for result in results:\n",
    "    keys = list(result.keys())\n",
    "    for key in keys:\n",
    "        if key.startswith(\"User\") and key.endswith(\"score\"):\n",
    "            result.pop(key)\n",
    "        if key.startswith(\"Assistant\") and key.endswith(\"score\"):\n",
    "            result.pop(key)\n",
    "\n",
    "# Add avg score\n",
    "score_keys = set()\n",
    "for result in results:\n",
    "    user_scores = []\n",
    "    for key in result:\n",
    "        if key.startswith(\"User\"):\n",
    "            user_scores.append(result[key][\"score\"])\n",
    "            score_keys.add(key)\n",
    "    result[\"avg_user_score\"] = sum(user_scores) / len(user_scores)\n",
    "\n",
    "    assistant_scores = []\n",
    "    for key in result:\n",
    "        if key.startswith(\"Assistant\"):\n",
    "            assistant_scores.append(result[key][\"score\"])\n",
    "            score_keys.add(key)\n",
    "    result[\"avg_assistant_score\"] = sum(assistant_scores) / len(assistant_scores)\n",
    "\n",
    "    result[\"avg_score\"] = (result[\"avg_user_score\"] + result[\"avg_assistant_score\"]) / 2\n",
    "    result[\"min_score\"] = min(user_scores + assistant_scores)\n",
    "\n",
    "# Add score_keys per result\n",
    "final_score_keys = []\n",
    "for result in results:\n",
    "    for key in score_keys:\n",
    "        if key.startswith(\"User\") or key.startswith(\"Assistant\"):\n",
    "            result[f\"{key} - score\"] = result[key][\"score\"]\n",
    "            final_score_keys.append(f\"{key} - score\")\n",
    "\n",
    "\n",
    "sorted_results = sorted(results, key=lambda x: x[\"min_score\"], reverse=True)\n",
    "df_inspection = pd.DataFrame(sorted_results)\n",
    "df_inspection[[\"colab_link\", \"avg_score\", \"min_score\", \"avg_user_score\", \"avg_assistant_score\"]+list(set(final_score_keys))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize Issues\n",
    "# Summarize Praises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colab_link</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>min_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://colab.research.google.com/drive/175sjDNLnaJQ429BrGb92T53_trPLMkkj</td>\n",
       "      <td>4.875000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://colab.research.google.com/drive/1ByZOC4TabPNL6wwBz4Y7GarX14z9qgYE</td>\n",
       "      <td>4.791667</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://colab.research.google.com/drive/1lhfB2DDg_YBKMpJY1t8VMswtZmty8LPb</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://colab.research.google.com/drive/14JlJxTxWt-jiyHXAVZGxjbcB5cFP95Se</td>\n",
       "      <td>4.708333</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>https://colab.research.google.com/drive/1Zoem75shOFo0kAJXuC8u0f9CSbh6EdxD</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>https://colab.research.google.com/drive/1MmTEwDoiiNbQPfUTVf8xvOCEdnGqOO7R</td>\n",
       "      <td>4.541667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>https://colab.research.google.com/drive/1kHLrjl22MzhMpqejBKGV_p52dXgJrT6u</td>\n",
       "      <td>4.541667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>https://colab.research.google.com/drive/1Udi670oeEb5lrRo3ZjfU_Og_s3iWij5e</td>\n",
       "      <td>4.541667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>https://colab.research.google.com/drive/1SiJ8Vlzw59_t5hjkqiSMNhaTZbwfNVDm</td>\n",
       "      <td>4.541667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>https://colab.research.google.com/drive/1_2bd6UIHl6NTqehcmzDfocmdwNvUl5Fk</td>\n",
       "      <td>4.541667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    colab_link  \\\n",
       "0    https://colab.research.google.com/drive/175sjDNLnaJQ429BrGb92T53_trPLMkkj   \n",
       "2    https://colab.research.google.com/drive/1ByZOC4TabPNL6wwBz4Y7GarX14z9qgYE   \n",
       "6    https://colab.research.google.com/drive/1lhfB2DDg_YBKMpJY1t8VMswtZmty8LPb   \n",
       "1    https://colab.research.google.com/drive/14JlJxTxWt-jiyHXAVZGxjbcB5cFP95Se   \n",
       "193  https://colab.research.google.com/drive/1Zoem75shOFo0kAJXuC8u0f9CSbh6EdxD   \n",
       "..                                                                         ...   \n",
       "27   https://colab.research.google.com/drive/1MmTEwDoiiNbQPfUTVf8xvOCEdnGqOO7R   \n",
       "194  https://colab.research.google.com/drive/1kHLrjl22MzhMpqejBKGV_p52dXgJrT6u   \n",
       "77   https://colab.research.google.com/drive/1Udi670oeEb5lrRo3ZjfU_Og_s3iWij5e   \n",
       "201  https://colab.research.google.com/drive/1SiJ8Vlzw59_t5hjkqiSMNhaTZbwfNVDm   \n",
       "174  https://colab.research.google.com/drive/1_2bd6UIHl6NTqehcmzDfocmdwNvUl5Fk   \n",
       "\n",
       "     avg_score  min_score  \n",
       "0     4.875000          4  \n",
       "2     4.791667          4  \n",
       "6     4.750000          3  \n",
       "1     4.708333          4  \n",
       "193   4.625000          2  \n",
       "..         ...        ...  \n",
       "27    4.541667          2  \n",
       "194   4.541667          2  \n",
       "77    4.541667          2  \n",
       "201   4.541667          2  \n",
       "174   4.541667          2  \n",
       "\n",
       "[79 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inspection[df_inspection[\"avg_score\"] > 4.5][[\"colab_link\", \"avg_score\", \"min_score\"]].sort_values(\"avg_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colab_link</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>min_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>https://colab.research.google.com/drive/189Fnel9xYNfdHXLDhwp83We0qiHvTcG-</td>\n",
       "      <td>3.958333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>https://colab.research.google.com/drive/10Eaapm9QHczC7D3AAU7SRm5jX70w16mi</td>\n",
       "      <td>3.958333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>https://colab.research.google.com/drive/1ZwYLCMAT-FzwuHFpQTYb37QmjBFKaVut</td>\n",
       "      <td>3.958333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>https://colab.research.google.com/drive/12g24t7usMca4XSvCOxTaARp9tA-S0uTA</td>\n",
       "      <td>3.958333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>https://colab.research.google.com/drive/1U06MSGGVC5iCHMdifnWKDpxWeFQ9YhiY</td>\n",
       "      <td>3.958333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>https://colab.research.google.com/drive/1VYI0x8yotTDhg10V8-8X1OX4dDMDZixX</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>https://colab.research.google.com/drive/1_687ZHrSOh_YakEusuT8omXtQWcP4Kwn</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>https://colab.research.google.com/drive/1NNZsKjc4-uBWN_OExf-F4mGADktzPCZc</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>https://colab.research.google.com/drive/1n4u7Uk0ix9bUx16-gC3RpABRfeb2POQh</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>https://colab.research.google.com/drive/1yMsSrVTwGXtZ4QSsDlI7o6bgJQaN4KTW</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    colab_link  \\\n",
       "698  https://colab.research.google.com/drive/189Fnel9xYNfdHXLDhwp83We0qiHvTcG-   \n",
       "507  https://colab.research.google.com/drive/10Eaapm9QHczC7D3AAU7SRm5jX70w16mi   \n",
       "635  https://colab.research.google.com/drive/1ZwYLCMAT-FzwuHFpQTYb37QmjBFKaVut   \n",
       "510  https://colab.research.google.com/drive/12g24t7usMca4XSvCOxTaARp9tA-S0uTA   \n",
       "542  https://colab.research.google.com/drive/1U06MSGGVC5iCHMdifnWKDpxWeFQ9YhiY   \n",
       "..                                                                         ...   \n",
       "629  https://colab.research.google.com/drive/1VYI0x8yotTDhg10V8-8X1OX4dDMDZixX   \n",
       "451  https://colab.research.google.com/drive/1_687ZHrSOh_YakEusuT8omXtQWcP4Kwn   \n",
       "706  https://colab.research.google.com/drive/1NNZsKjc4-uBWN_OExf-F4mGADktzPCZc   \n",
       "666  https://colab.research.google.com/drive/1n4u7Uk0ix9bUx16-gC3RpABRfeb2POQh   \n",
       "458  https://colab.research.google.com/drive/1yMsSrVTwGXtZ4QSsDlI7o6bgJQaN4KTW   \n",
       "\n",
       "     avg_score  min_score  \n",
       "698   3.958333          1  \n",
       "507   3.958333          1  \n",
       "635   3.958333          1  \n",
       "510   3.958333          1  \n",
       "542   3.958333          1  \n",
       "..         ...        ...  \n",
       "629   2.875000          1  \n",
       "451   2.500000          1  \n",
       "706   2.166667          1  \n",
       "666   1.833333          1  \n",
       "458   1.333333          1  \n",
       "\n",
       "[79 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inspection[df_inspection[\"avg_score\"] < 4][[\"colab_link\", \"avg_score\", \"min_score\"]].sort_values(\"avg_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colab_link</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>avg_user_score</th>\n",
       "      <th>avg_assistant_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://colab.research.google.com/drive/175sjDNLnaJQ429BrGb92T53_trPLMkkj</td>\n",
       "      <td>4.875000</td>\n",
       "      <td>4.75</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://colab.research.google.com/drive/14JlJxTxWt-jiyHXAVZGxjbcB5cFP95Se</td>\n",
       "      <td>4.708333</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://colab.research.google.com/drive/1ByZOC4TabPNL6wwBz4Y7GarX14z9qgYE</td>\n",
       "      <td>4.791667</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://colab.research.google.com/drive/1qdJCb-is1XBWjjS1GOS8FwE8C4Hr4Nmx</td>\n",
       "      <td>4.291667</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://colab.research.google.com/drive/1PLC-pIdI0kI2ePnFkFuEDFSKrPPqq1ES</td>\n",
       "      <td>4.541667</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>https://colab.research.google.com/drive/1SesHn312-K9j33_o6gHg458AS7tWgL-z</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>https://colab.research.google.com/drive/1NscBf5dfsaJu3OWC2TGKHWNK-gJIzFKM</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>https://colab.research.google.com/drive/1FVLxbQs_H2qcSj1j2Qla40tqN87IQm7v</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>https://colab.research.google.com/drive/1qheya6A3_ZYkyAP4-cbe5q5DIyoY8MRJ</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>https://colab.research.google.com/drive/1l_uDM7Q3rDRynN6lXbNGq69AgLObkMyv</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>715 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    colab_link  \\\n",
       "0    https://colab.research.google.com/drive/175sjDNLnaJQ429BrGb92T53_trPLMkkj   \n",
       "1    https://colab.research.google.com/drive/14JlJxTxWt-jiyHXAVZGxjbcB5cFP95Se   \n",
       "2    https://colab.research.google.com/drive/1ByZOC4TabPNL6wwBz4Y7GarX14z9qgYE   \n",
       "3    https://colab.research.google.com/drive/1qdJCb-is1XBWjjS1GOS8FwE8C4Hr4Nmx   \n",
       "4    https://colab.research.google.com/drive/1PLC-pIdI0kI2ePnFkFuEDFSKrPPqq1ES   \n",
       "..                                                                         ...   \n",
       "710  https://colab.research.google.com/drive/1SesHn312-K9j33_o6gHg458AS7tWgL-z   \n",
       "711  https://colab.research.google.com/drive/1NscBf5dfsaJu3OWC2TGKHWNK-gJIzFKM   \n",
       "712  https://colab.research.google.com/drive/1FVLxbQs_H2qcSj1j2Qla40tqN87IQm7v   \n",
       "713  https://colab.research.google.com/drive/1qheya6A3_ZYkyAP4-cbe5q5DIyoY8MRJ   \n",
       "714  https://colab.research.google.com/drive/1l_uDM7Q3rDRynN6lXbNGq69AgLObkMyv   \n",
       "\n",
       "     avg_score  avg_user_score  avg_assistant_score  \n",
       "0     4.875000            4.75             5.000000  \n",
       "1     4.708333            4.75             4.666667  \n",
       "2     4.791667            4.75             4.833333  \n",
       "3     4.291667            4.25             4.333333  \n",
       "4     4.541667            4.75             4.333333  \n",
       "..         ...             ...                  ...  \n",
       "710   4.333333            4.00             4.666667  \n",
       "711   4.333333            4.00             4.666667  \n",
       "712   4.250000            4.00             4.500000  \n",
       "713   4.250000            4.00             4.500000  \n",
       "714   3.916667            4.00             3.833333  \n",
       "\n",
       "[715 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 3 * pd.get_option('display.max_colwidth'))\n",
    "\n",
    "df_inspection[[\"colab_link\", \"avg_score\", \"avg_user_score\", \"avg_assistant_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sheets_utils import upload_df_to_sheet\n",
    "\n",
    "\n",
    "service_account_path = \"../../cres/google__sa.json\"\n",
    "tracking_sheet_id = \"1qBU7Kvuuij2fxbqPxebReKMxWgIBmOIE5Gi4ZuX0j_4\"\n",
    "\n",
    "upload_df_to_sheet(\n",
    "    service_account_path=service_account_path,\n",
    "    sheet_id=tracking_sheet_id,\n",
    "    sheet_name=\"\",\n",
    "    df=df_inspection[[\"colab_link\", \"avg_score\", \"avg_user_score\", \"avg_assistant_score\"]],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
