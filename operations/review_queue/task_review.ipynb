{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "import numpy as np\n",
    "#from src.sheets_utils import download_sheet_as_df\n",
    "from src.sheets_utils import upload_df_to_sheet\n",
    "from src.sheets_utils import create_new_sheet_from_df\n",
    "\n",
    "import json\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "import schedule\n",
    "from schedule import every, repeat, run_pending\n",
    "\n",
    "pd.set_option('display.max_columns', 5)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "\n",
    "service_account_path = \"creds/google__sa.json\"\n",
    "tracking_sheet_id = \"1qBU7Kvuuij2fxbqPxebReKMxWgIBmOIE5Gi4ZuX0j_4\"\n",
    "delivery_sheet_id = \"1eUif5I8xhHU8fY0X9v8r2JI9hWPh7Dq_9VXpSIHwww4\"\n",
    "delivered_batches=[]\n",
    "review_batches=[]\n",
    "num_task_sheets=0\n",
    "num_delivered_batches=0\n",
    "is_first_run=0\n",
    "task_df=None\n",
    "review_df=None\n",
    "delivered_df=None\n",
    "current=None\n",
    "oldReviews=None\n",
    "review_sheet=None\n",
    "reviewSheet = \"Review_Queue_Latest\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_sheets_as_df(service_account_path, sheet_id, sheet_name):\n",
    "    # Authenticate with the service account\n",
    "    scopes = ['https://www.googleapis.com/auth/spreadsheets.readonly']\n",
    "    creds = service_account.Credentials.from_service_account_file(\n",
    "        service_account_path, scopes=scopes)\n",
    "    service = build('sheets', 'v4', credentials=creds)\n",
    "\n",
    "    # Construct the range to read\n",
    "    sheet_range = f\"{sheet_name}!A:Z\"  # Adjust the range A:Z as needed\n",
    "\n",
    "    # Make the API request\n",
    "    result = service.spreadsheets().values().get(\n",
    "        spreadsheetId=sheet_id, range=sheet_range).execute()\n",
    "    values = result.get('values', [])\n",
    "\n",
    "    # Convert to a DataFrame\n",
    "    if not values:\n",
    "        #print(\"No data found.\")\n",
    "        return pd.DataFrame()\n",
    "    else:\n",
    "        #return pd.DataFrame.from_records(values[1:],columns=values[0])\n",
    "        return pd.DataFrame([row + [None] * (len(values[0]) - len(row)) for row in values[1:]], columns=values[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sheets(service_account_path, sheet_id,sheet_val):\n",
    "    # Authenticate with the service account\n",
    "    scopes = ['https://www.googleapis.com/auth/spreadsheets.readonly']\n",
    "    creds = service_account.Credentials.from_service_account_file(\n",
    "        service_account_path, scopes=scopes)\n",
    "    service = build('sheets', 'v4', credentials=creds)\n",
    "    values=[]\n",
    "    # Construct the range to read\n",
    "    sheet = service.spreadsheets().get(spreadsheetId=sheet_id).execute().get('sheets', [])\n",
    "    for s in sheet:\n",
    "        sheet_title = s.get('properties', {}).get('title')\n",
    "        if(sheet_val in sheet_title):\n",
    "            # Construct the range to read\n",
    "            sheet_range = f\"{sheet_title}!A:Z\"  # Adjust the range A:Z as needed\n",
    "            # Make the API request\n",
    "            result = service.spreadsheets().values().get(\n",
    "            spreadsheetId=sheet_id, range=sheet_range).execute()\n",
    "            val = result.get('values', [])\n",
    "            if(val):\n",
    "                if val[0] and sheet_title not in values:\n",
    "                    values.append(sheet_title)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_date(date):\n",
    "    \"\"\"\n",
    "    Given a date string, standardize the date format to MM/DD/YYYY.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Parse the date string into a datetime object\n",
    "        standard_date = datetime.strptime(date, \"%m/%d/%Y\")\n",
    "    except ValueError:\n",
    "        try:\n",
    "            # Attempt to parse other common formats here\n",
    "            # Example: DD/MM/YYYY\n",
    "            standard_date = datetime.strptime(date, \"%d/%m/%Y\")\n",
    "        except ValueError:\n",
    "            return \"\"\n",
    "\n",
    "    # Format the datetime object into the desired string format\n",
    "    return standard_date.strftime(\"%m/%d/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diff_data(first,second):\n",
    "    values = set(second['task_link'])\n",
    "    #print(\"length of second df : \",len(values))\n",
    "    first['match'] = first['task_link'].isin(values).astype(int)\n",
    "    result = first[~(first['match']==1)]\n",
    "    return result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_review_tasks():\n",
    "    global review_batches \n",
    "    global num_task_sheets\n",
    "    global delivered_batches\n",
    "    global task_df\n",
    "    global review_df\n",
    "    global delivered_df\n",
    "    global oldReviews\n",
    "    global current\n",
    "    global review_sheet\n",
    "    global is_first_run\n",
    "    task_df = None\n",
    "    delivered_df=None\n",
    "    current=None\n",
    "    oldReviews=None    \n",
    "    tasks_val = 'Conversations_Batch_'\n",
    "    delivery_val = 'Batch '\n",
    "    reviews_val = 'Reviews'\n",
    "    review_batches = get_sheets(\n",
    "        service_account_path,\n",
    "        tracking_sheet_id,\n",
    "        tasks_val\n",
    "    )\n",
    "    #Check sheets available with tasks completed and not delivered\n",
    "    num_task_sheets = len(review_batches)\n",
    "    delivered_batches = get_sheets(service_account_path,delivery_sheet_id,delivery_val)\n",
    "    num_delivered_batches = len(delivered_batches)\n",
    "    if(is_first_run==0):\n",
    "        current=pd.DataFrame(columns=['task_link','assigned_to_email','completion_date','reviewer_email','review_status'])\n",
    "    for s in review_batches:        \n",
    "        task_df = pd.concat([\n",
    "            task_df,\n",
    "        download_sheets_as_df(\n",
    "            service_account_path,\n",
    "            tracking_sheet_id,\n",
    "            s\n",
    "        )],ignore_index=True)\n",
    "        #print(\"Number of tasks : \",len(task_df))\n",
    "    for d in delivered_batches:          \n",
    "        delivered_df = pd.concat([\n",
    "            delivered_df,\n",
    "        download_sheets_as_df(\n",
    "            service_account_path,\n",
    "            delivery_sheet_id,\n",
    "            d\n",
    "        )],ignore_index=True)    \n",
    "    oldReviews = pd.concat([\n",
    "                download_sheets_as_df(\n",
    "                    service_account_path,\n",
    "                    tracking_sheet_id,\n",
    "                    'Reviews'\n",
    "                )], ignore_index=True)\n",
    "    current = download_sheets_as_df(\n",
    "            service_account_path,\n",
    "            tracking_sheet_id,\n",
    "            reviewSheet)\n",
    "    #Formulate review dataframe \n",
    "    delivered_df.drop_duplicates(subset='task_link',keep='first')\n",
    "    #delivered_df.dropna(subset=[\"task_link\"], axis=0,inplace=True)\n",
    "    #task_df.dropna(subset=[\"task_link\"], axis=0,inplace=True)    \n",
    "    task_df = task_df[(task_df[\"completion_status\"]==\"Done\")]    \n",
    "    review_sheet=pd.DataFrame(columns=['task_link','assigned_to_email','completion_date','reviewer_email','review_status'])\n",
    "    review_df=pd.DataFrame(columns=task_df.columns)\n",
    "    #print(\"Number of Completed tasks : \",len(task_df))\n",
    "    #print(\" Number of Delivered tasks : \",len(delivered_df))\n",
    "    values = set(delivered_df['task_link'])\n",
    "    task_df['match'] = task_df['task_link'].isin(values).astype(int)\n",
    "    review_df = task_df[~(task_df['match']==1)]\n",
    "    #print('Tasks eligible for review : ',len(review_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_df_to_review_sheet(rs):\n",
    "    global is_first_run\n",
    "    global reviewSheet\n",
    "    global review_sheet\n",
    "    if(is_first_run==0 and (current.empty)):\n",
    "        #print('first_run not set yet..',len(rs))\n",
    "        create_new_sheet_from_df(service_account_path,tracking_sheet_id,\"Review_Queue_Latest\",rs)\n",
    "        is_first_run=1           \n",
    "    else:\n",
    "        res = rs[1:].copy(deep=True)\n",
    "        res.columns = [''] * len(res.columns) \n",
    "        create_new_sheet_from_df(service_account_path,tracking_sheet_id,\"Review_Queue_Latest\",res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tasks_to_review_queue():\n",
    "    global review_df\n",
    "    global oldReviews\n",
    "    global current\n",
    "    global review_sheet\n",
    "    global is_first_run \n",
    "    try:\n",
    "        init_review_tasks()\n",
    "        review_df.loc[review_df['completion_date'].isnull(),'completion_date'] = ''\n",
    "        #review_df.loc[:,'completion_date'] = review_df.loc[:,'completion_date'].apply(lambda x:standardize_date(x))\n",
    "        review_df_copy = review_df.copy()\n",
    "        # Modify the column value using the .loc syntax and the function\n",
    "        review_df_copy.loc[:,'completion_date'] = review_df_copy.loc[:,'completion_date'].apply(lambda x:standardize_date(x))\n",
    "        review_df = review_df_copy.copy()\n",
    "        print('Check Tasks for Review at :',datetime.now())               \n",
    "        #Add max 30% of total tasks for review\n",
    "        #print(current.head())\n",
    "        if(current is not None and len(current.index)!=0):        \n",
    "            review_df = get_diff_data(review_df,current)\n",
    "        df=review_df.groupby(['assigned_to_email','completion_date']).agg({'task_link':'count'}).sort_values(by=['task_link'],ascending=[False]).reset_index(level=['assigned_to_email','completion_date'])\n",
    "        print('Number of unique members worked on current batch tasks :',df['assigned_to_email'].nunique())\n",
    "        members = df['assigned_to_email'].unique()\n",
    "        total_tasks = len(review_df)\n",
    "        print('Number of completed tasks in current batch ',total_tasks)\n",
    "        review_tasks = int(round(total_tasks*0.3,2))\n",
    "        print('Number of tasks to be considered for review ',review_tasks)\n",
    "        count=0\n",
    "        for person in members:  #select one task for each member            \n",
    "            for index,row in review_df.iterrows():                              \n",
    "                if row['assigned_to_email']==person and (person not in set(review_sheet['assigned_to_email']) and row['task_link'] not in set(review_sheet['task_link'])):        \n",
    "                    newRow = {'task_link':row['task_link'],'assigned_to_email':row['assigned_to_email'],'completion_date':row['completion_date'],'reviewer_email':\"\",'review_status':\"\"}\n",
    "                    review_sheet.loc[len(review_sheet.index)] = newRow                    \n",
    "                    count=count+1\n",
    "                    break\n",
    "            if(count>=review_tasks):\n",
    "                break\n",
    "        print('Added ',count,\" tasks for review to consider all contributors\")\n",
    "        if(count>=review_tasks):\n",
    "            add_df_to_review_sheet(review_sheet)\n",
    "            return\n",
    "        else:\n",
    "            oldReviews.dropna(subset=[\"Email Address\"], inplace=True)\n",
    "            oldReviews['Code Quality'] = oldReviews['Code Quality'].astype(int)\n",
    "            oldReviews = oldReviews[oldReviews['Code Quality']<=3]\n",
    "            old_members = oldReviews['Email Address'].unique()\n",
    "            old_list = list(set(members).intersection(old_members)) #old contributors in current task list\n",
    "            print('Number of contributors with low code quality :',len(old_list))\n",
    "            old=0\n",
    "            for person in old_list:  #select one task for each member\n",
    "                for index1,row1 in review_df.iterrows():\n",
    "                    if row1['assigned_to_email']==person and (row1['task_link'] not in set(review_sheet['task_link'])):\n",
    "                        #print('Adding old review data :',row1['task_link'])\n",
    "                        newRow = {'task_link':row1['task_link'],'assigned_to_email':row1['assigned_to_email'],'completion_date':row1['completion_date'],'reviewer_email':\"\",'review_status':\"\"}\n",
    "                        review_sheet.loc[len(review_sheet.index)] = newRow\n",
    "                        count=count+1\n",
    "                        old=old+1\n",
    "                        break\n",
    "                if(count>=review_tasks):\n",
    "                    break\n",
    "            print('Added old review low quality member tasks to the sheet ',old+1)\n",
    "            if(count>=review_tasks):\n",
    "                add_df_to_review_sheet(review_sheet)\n",
    "                return\n",
    "            else:\n",
    "                if(current is not None and len(current.index)!=0): \n",
    "                    review_df = get_diff_data(review_df,current)\n",
    "                df=review_df.groupby(['assigned_to_email','completion_date']).agg({'task_link':'count'}).sort_values(by=['task_link'],ascending=[False]).reset_index(level=['assigned_to_email','completion_date'])\n",
    "                major_contributors=df[df['task_link']>=4]\n",
    "                mem = major_contributors['assigned_to_email'].unique()\n",
    "                print('Number of contributors with high number of tasks :',len(mem))\n",
    "                high=0\n",
    "                for person in mem:\n",
    "                    for index,row in review_df.iterrows():\n",
    "                        if(row['assigned_to_email']==person and row['task_link'] not in set(review_sheet['task_link'])):\n",
    "                            newRow = {'task_link':row['task_link'],'assigned_to_email':row['assigned_to_email'],'completion_date':row['completion_date'],'reviewer_email':\"\",'review_status':\"\"}\n",
    "                            review_sheet.loc[len(review_sheet.index)] = newRow    \n",
    "                            count=count+1\n",
    "                            high=high+1\n",
    "                            break                        \n",
    "                    if(count>=review_tasks):\n",
    "                        break\n",
    "                #Update review sheet and complete current iteration now                \n",
    "                print('Members with high number of tasks considered for review now : ',high)           \n",
    "                add_df_to_review_sheet(review_sheet)\n",
    "                return     \n",
    "    except HttpError as e:\n",
    "        error_reason = json.loads(e.content)['error']\n",
    "        error_details = e.error_details \n",
    "        print(error_reason)\n",
    "        print(error_details)\n",
    "    except Exception as e:\n",
    "        error_reason = json.loads(e.content)['error']\n",
    "        error_details = e.error_details \n",
    "        print(error_reason)\n",
    "        print(error_details)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init_review_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_tasks_to_review_queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run job every hour at the  minute\n",
    "def main():\n",
    "    schedule.every(1).minutes.do(add_tasks_to_review_queue)\n",
    "    while True:\n",
    "        schedule.run_pending()\n",
    "        time.sleep(1*60) #Check hourly updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
