{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "client = OpenAI()\n",
    "\n",
    "user_prompt_template_m_turns = \"\"\"\n",
    "[Instruction]\\nPlease act as an impartial judge and evaluate the quality of the response provided by an AI assistant to the user question displayed below. \n",
    "Your evaluation should consider factors such as the helpfulness, relevance, accuracy, depth, creativity, and level of detail of the response.\n",
    "Begin your evaluation by providing a short explanation. Be as objective as possible.\n",
    "After providing your explanation, you must rate the response on a scale of 1 to 10 by strictly following this format: \\\"[[rating]]\\\", \n",
    "for example: \\\"Rating: [[5]]\\\".\\n\\n\n",
    "There may be multiple turns of conversations between user and AI assistant.\n",
    "[Conversation]\\n{content}\\n[The End of Conversation]\\n\n",
    "\"\"\"\n",
    "\n",
    "def llm_reviewer_m_turns(content):\n",
    "    try:\n",
    "        # Format the user_prompt_template with the question and answer\n",
    "        formatted_prompt = user_prompt_template_m_turns.format(content=content)\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4-1106-preview\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": formatted_prompt}\n",
    "            ],\n",
    "            temperature = 0.0,\n",
    "            seed = 42,\n",
    "            max_tokens = 1024,\n",
    "            #logprobs = True\n",
    "        )\n",
    "        questions = response.choices[0].message.content\n",
    "        return questions\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Could you help me refactor this greedy algorithm that's supposed to find the minimum number of platforms needed at a railway station to avoid any delay in arrival of any train? I'd like it to also return the schedule of trains (as pairs of arrival and departure times) for each platform. Here's the current code: ```python def findPlatform(arrival, departure): arrival.sort() departure.sort() plat_needed = 1 result = 1 i = 1 j = 0 while i < len(arrival) and j < len(departure): if arrival[i] <= departure[j]: plat_needed += 1 i += 1 else: plat_needed -= 1 j += 1 if plat_needed > result: result = plat_needed return result ```\n",
      "Assistant: In order to achieved what you have asked, you will need to use a much more complex or detailed code so that we can track which train goes to which platform properly.\n",
      "\n",
      "Here is good way to go about this:\n",
      "Assistant: def findPlatform(arrival, departure):\n",
      "    events = sorted([(t, 'a') for t in arrival] + [(t, 'd') for t in departure])\n",
      "\n",
      "    plat_needed = 0\n",
      "    max_plat_needed = 0\n",
      "    platform_schedule = {}\n",
      "    current_trains = []\n",
      "\n",
      "    for time, event in events:\n",
      "        if event == 'a':\n",
      "            plat_needed += 1\n",
      "            current_trains.append(time)\n",
      "            if plat_needed > max_plat_needed:\n",
      "                max_plat_needed = plat_needed\n",
      "                platform_schedule[max_plat_needed] = [current_trains[-1]]\n",
      "        else:\n",
      "            plat_needed -= 1\n",
      "            departure_train = next((train for train in current_trains if train <= time), None)\n",
      "            if departure_train:\n",
      "                current_trains.remove(departure_train)\n",
      "                for p in range(1, max_plat_needed + 1):\n",
      "                    if platform_schedule.get(p) and platform_schedule[p][-1] == departure_train:\n",
      "                        platform_schedule[p].append(time)\n",
      "                        break\n",
      "            else:\n",
      "                # In case there's no matching arrival (should not happen in a correct input)\n",
      "                continue\n",
      "\n",
      "    # Convert the schedule to pairs of arrival and departure for each platform\n",
      "    final_schedule = {p: [(platform_schedule[p][i], platform_schedule[p][i+1]) for i in range(0, len(platform_schedule[p]), 2)] for p in platform_schedule}\n",
      "\n",
      "    return max_plat_needed, final_schedule\n",
      "\n",
      "\n",
      "# Example usage\n",
      "arrival = [900, 940, 950, 1100, 1500, 1800]\n",
      "departure = [910, 1200, 1120, 1130, 1900, 2000]\n",
      "\n",
      "platforms_needed, schedule = findPlatform(arrival, departure)\n",
      "print(\"Minimum Number of Platforms Required =\", platforms_needed)\n",
      "print(\"Platform Schedule =\", schedule)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Assuming the file 'task_1.jsonl' is in the same directory as this script\n",
    "file_path = 'task_1.jsonl'\n",
    "\n",
    "# Read the file and process each line\n",
    "conversation_string = ''\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        obj = json.loads(line)\n",
    "        conversation_string += obj['role'] + \": \" + obj['content'] + '\\n'\n",
    "\n",
    "print(conversation_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AI assistant's response is helpful and relevant to the user's request. It provides a refactored version of the algorithm that not only finds the minimum number of platforms needed but also returns the schedule of trains for each platform. The code is accurate and demonstrates a good understanding of the problem by sorting the events (both arrivals and departures) and iterating through them to allocate platforms and schedule trains accordingly.\n",
      "\n",
      "The assistant's solution uses a list of tuples to track events, a smart way to handle the arrivals and departures in a single sorted list. The code also includes comments that help explain the logic, which is a good practice for code readability and maintenance.\n",
      "\n",
      "However, there are a few points that could be improved or clarified:\n",
      "1. The code assumes that each train's arrival and departure times are unique, which may not always be the case in real-world scenarios.\n",
      "2. The code does not handle edge cases where a departure time could be earlier than any arrival time, which could happen if the input data is not pre-validated.\n",
      "3. The code snippet provided by the assistant is incomplete; it does not show the entire function definition or the necessary indentation, which is crucial in Python.\n",
      "\n",
      "Despite these points, the assistant's response is creative and provides a detailed solution to the user's problem. It could be improved by addressing the potential edge cases and ensuring the code is complete and correctly formatted.\n",
      "\n",
      "Rating: [[7]]\n"
     ]
    }
   ],
   "source": [
    "rating = llm_reviewer_m_turns(conversation_string)\n",
    "if rating:\n",
    "    print(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "directory_path = 'batch_2_results'\n",
    "ratings = []\n",
    "\n",
    "# Open a text file to write the ratings\n",
    "with open('llm_reviews.txt', 'w') as record_file:\n",
    "    # Loop through each file in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.jsonl'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            conversation_string = ''\n",
    "            \n",
    "            # Read the file and process each line\n",
    "            with open(file_path, 'r') as file:\n",
    "                for line in file:\n",
    "                    obj = json.loads(line)\n",
    "                    conversation_string += obj['role'] + \": \" + obj['content'] + '\\n'\n",
    "            \n",
    "            # Get the rating for the current file\n",
    "            rating = llm_reviewer_m_turns(conversation_string)\n",
    "            if rating:\n",
    "                ratings.append((filename, rating))\n",
    "                # Write the rating into the text file\n",
    "                record_file.write(f\"{filename}: {rating}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
